{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Essay Generator\n",
    "\n",
    "This notebook is an attempt to automatically generate a high scoring essay. For simplicity the text basis is limited to the highest scoring essays from topic number 1 (\"Computers\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2dfcb8c657ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# nlp = spacy.load('en') # not needed for character based generation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Load LSTM network and generate text\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "# spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp = spacy.load('en') # not needed for character based generation.\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_pickle('training_corr.pkl')\n",
    "\n",
    "\n",
    "# for clarity, rename numbered essay topics to one-word topic summary \n",
    "\n",
    "topic_dict = {'topic':{1: 'computers', \n",
    "                       2: 'censorship', \n",
    "                       3: 'cyclist', \n",
    "                       4: 'hibiscus', \n",
    "                       5: 'mood', \n",
    "                       6: 'dirigibles', \n",
    "                       7: 'patience', \n",
    "                       8: 'laughter'}}\n",
    "\n",
    "training_set.replace(topic_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ascii text and covert to lowercase\n",
    "# Select high scoring essays from two topics. \n",
    "# Use only language corrected essays.\n",
    "essays = training_set[((training_set.topic == 'computers') &\n",
    "         (training_set.target_score > 11))]['corrected']\n",
    "\n",
    "print(len(essays), 'essays used.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to prepare a list of units on which the sequence will be based. The units could be essays, sentences, words or characters. The smaller the unit, the smaller the vocabulary and the more efficient the training.\n",
    "\n",
    "Generally, a smart tokenizer such as SpaCy will return better tokens, for example, \"don't\" does not contain whitespace, but should be split into two tokens, \"do\" and \"n't\", while \"U.K.\" should always remain one token. For character based generation, using SpaCy doesn't add any value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single list of words from all essays\n",
    "texts = []\n",
    "for essay in essays:\n",
    "    essay = nlp(essay, disable=['parser', 'ner'])\n",
    "    texts.append([tok.text.lower() for tok in essay])\n",
    "\n",
    "# words/tokens\n",
    "tokens = [word for e in texts for word in e]\n",
    "\n",
    "# characters\n",
    "char_list = [char for word in tokens for char in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(tokens))) # or char_list\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# summarize the loaded data\n",
    "n_chars = len(tokens) # char_list\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 40\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = tokens[i:i + seq_length] # char_list\n",
    "    seq_out = tokens[i + seq_length] # char_list\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2, seed=42))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "optimizer = adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=40, batch_size=128, callbacks=callbacks_list, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights from most improved\n",
    "# filename = \"weights-character-base.hdf5\" # character\n",
    "filename = \"weights-improvement-40-3.9929.hdf5\" # word\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_prediction(prediction):\n",
    "    \"\"\"Get rand index from preds based on its prob distribution.\n",
    "\n",
    "    Params\n",
    "    ——\n",
    "    prediction (array (array)): array of length 1 containing array of probs that sums to 1\n",
    "\n",
    "    Returns\n",
    "    ——-\n",
    "    rnd_idx (int): random index from prediction[0]\n",
    "\n",
    "    Notes\n",
    "    —–\n",
    "    Helps to solve problem of repeated outputs.\n",
    "\n",
    "    len(prediction) = 1\n",
    "    len(prediction[0]) >> 1\n",
    "    \"\"\"\n",
    "    X = prediction[0] # sum(X) is approx 1\n",
    "    rnd_idx = np.random.choice(len(X), p=X)\n",
    "    return rnd_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = ''\n",
    "for i in range(400):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = sample_prediction(prediction)\n",
    "    result = int_to_char[index]\n",
    "    generated += result + ' '\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print('\\nDone.')\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character based essay generation\n",
    "\n",
    "Note that the space symbol was removed during tokenization. Nonetheless, it is still difficult to imagine where to separate the text into meaningful words.\n",
    "\n",
    "`\"Done.\n",
    "2nrarliutistrteveoppuneedtes,lhonnvao@onlatfzuhniesioeeplmstrrowiteeoieaninetooeoofeirhanpegy.nhaentlgruuaa,onsoencyeakss@edhabophdtrslailirueu.ehttmhneedsoeoadwmamftaecfts.ohoacetcsetenkypersecpmvpthcbnoyuees.ttecoiputeidvedyots'eveoaohwereesjranaptaegileeteeaedysyobcyiencposabtoeb-niheiatanol.oavaeecgfclnalbyaakts1snoaslhfabnheseailn1tenscmricptdsefnrnofoaboipiteilno?itp2nraoenrtirianppntetcsaue\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
